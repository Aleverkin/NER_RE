{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ebebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = char_ff_lstm_model\n",
    "\n",
    "inputs, true_labels = next(iter(train_loader))\n",
    "batch_size = inputs.size(0)\n",
    "_, logits = model(inputs.to(\"cuda\"), true_labels.to(\"cuda\"))\n",
    "\n",
    "predicted_labels = logits.argmax(dim=2).detach().cpu()\n",
    "\n",
    "ind = 10\n",
    "\n",
    "for i, j in zip(train_val[ind].labels,  predicted_labels[ind]):\n",
    "    print(i, int(j.item()))\n",
    "\n",
    "\n",
    "\n",
    "classes_count=len(ner_types)\n",
    "\n",
    "m = CRF(classes_count, batch_first=True)\n",
    "\n",
    "emissions = torch.randn(BATCH_SIZE, 500, classes_count)\n",
    "\n",
    "inputs, true_labels = next(iter(train_loader))\n",
    "\n",
    "BATCH_SIZE\n",
    "\n",
    "m(emissions, true_labels)\n",
    "\n",
    "173546 / 128\n",
    "\n",
    "num_tags = 5  # number of tags is 5\n",
    "model = CRF(num_tags)\n",
    "\n",
    "seq_length = 3  # maximum sequence length in a batch\n",
    "batch_size = 2  # number of samples in the batch\n",
    "emissions = torch.randn(seq_length, batch_size, num_tags)\n",
    "tags = torch.tensor([\n",
    "            [0, 1], [2, 4], [3, 1]], dtype=torch.long)  # (seq_length, batch_size)\n",
    "model(emissions, tags)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i, (true, pred) in enumerate(zip(global_true, global_pred)):\n",
    "    print(i, 'true: ', true, '\\t', 'pred: ', pred)\n",
    "\n",
    "predicted_labels\n",
    "\n",
    "test[ind].labels\n",
    "\n",
    "predicted_labels.shape\n",
    "\n",
    "train_val[ind].labels\n",
    "\n",
    "predicted_labels[ind]\n",
    "\n",
    "train_val[ind].tokens\n",
    "\n",
    "train_val[ind].spans\n",
    "\n",
    "train_val[0].labels\n",
    "\n",
    "predicted_labels[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Метрики\n",
    "\n",
    "Можно использовать как классические мультиклассификационнные метрики, так и метрики специально для NER.\n",
    "\n",
    "Например, число точных и частичных совпадений спанов, пропущенных и лишних спанов.\n",
    "\n",
    "def get_spans(labels, tokens):\n",
    "    spans = []\n",
    "    for i, (label, token) in enumerate(zip(labels, tokens)):\n",
    "        if label == 1:\n",
    "            spans.append((token.start, token.stop, \"PER\"))\n",
    "        elif label == 2:\n",
    "            assert len(spans) != 0, \"Incorrect label sequence: {}\".format(labels)\n",
    "            old_begin, _, old_tag = spans[-1]\n",
    "            spans[-1] = (old_begin, token.stop, old_tag)\n",
    "    return spans\n",
    "\n",
    "\n",
    "def compare_span_sets(left_spans, right_spans):\n",
    "    exact, partial, missing = 0, 0, 0\n",
    "    for left_span in left_spans:\n",
    "        is_missing = True\n",
    "        for right_span in right_spans:\n",
    "            if left_span == right_span:\n",
    "                exact += 1\n",
    "                is_missing = False\n",
    "                break\n",
    "            ls, le, _ = left_span\n",
    "            rs, re, _ = right_span\n",
    "            # [ls le] [rs re]\n",
    "            # [rs re] [ls le]\n",
    "            if not (ls <= le <= rs <= re or rs <= re <= ls <= le):\n",
    "                is_missing = False\n",
    "                partial += 1\n",
    "                break            \n",
    "        if is_missing:\n",
    "            missing += 1\n",
    "    return exact, partial, missing\n",
    "\n",
    "\n",
    "def calc_metrics(true_labels, predicted_labels, tokens):\n",
    "    # Метрики классификации\n",
    "    one_tp, one_fp, one_fn = 0, 0, 0\n",
    "    for true, predicted in zip(true_labels, predicted_labels):\n",
    "        for l1, l2 in zip(true, predicted):\n",
    "            if l1 == 1 and l2 == 1:\n",
    "                one_tp += 1\n",
    "            elif l1 != 1 and l2 == 1:\n",
    "                one_fp += 1\n",
    "            elif l1 == 1 and l2 !=1:\n",
    "                one_fn += 1\n",
    "    if one_tp + one_fp == 0:\n",
    "        print(\"No positives!\")\n",
    "    else:\n",
    "        print(\"1 Precision: {}, 1 Recall: {}\".format(float(one_tp)/(one_tp + one_fp), float(one_tp)/(one_tp + one_fn)))\n",
    "\n",
    "    # Специализированные метрики\n",
    "    e, p, m, s = 0, 0, 0, 0\n",
    "    for (true, predicted), sample_tokens in zip(zip(true_labels, predicted_labels), tokens):\n",
    "        true_spans = get_spans(true, sample_tokens)\n",
    "        predicted_spans = get_spans(predicted, sample_tokens)\n",
    "        exact, partial, missing = compare_span_sets(true_spans, predicted_spans)\n",
    "        _, _, spurius = compare_span_sets(predicted_spans, true_spans)\n",
    "        e += exact\n",
    "        p += partial\n",
    "        m += missing\n",
    "        s += spurius\n",
    "    print(\"Exact: {}, partial: {}, missing: {}, spurius: {}\".format(e, p, m, s))\n",
    "            \n",
    "\n",
    "\n",
    "def predict(model, test_loader, show_sample_index=51):\n",
    "    model.eval()\n",
    "    all_true_labels, all_predicted_labels, all_tokens, all_texts = [], [], [], []\n",
    "    for batch_index, batch in enumerate(test_loader):\n",
    "        inputs, true_labels = batch\n",
    "        batch_size = inputs.size(0)\n",
    "        _, logits = model(inputs.to(\"cuda\"), true_labels.to(\"cuda\"))\n",
    "        predicted_labels = logits.max(dim=1)[1].detach().cpu()\n",
    "\n",
    "        # Убираем неконсистентность BIO\n",
    "        for sample_num, sample in enumerate(predicted_labels):\n",
    "            for token_num, label in enumerate(sample):\n",
    "                if token_num == 0 and label == 2:\n",
    "                    predicted_labels[sample_num][0] = 1\n",
    "                    continue\n",
    "                prev_label = sample[token_num - 1]\n",
    "                if label == 2 and prev_label == 0:\n",
    "                    predicted_labels[sample_num][token_num] = 1\n",
    "\n",
    "        all_true_labels.extend(true_labels)\n",
    "        all_predicted_labels.extend(predicted_labels)\n",
    "        for i in range(batch_size):\n",
    "            all_tokens.append(test_data.get_tokens(batch_index * batch_size + i))\n",
    "            all_texts.append(test_data.get_text(batch_index * batch_size + i))\n",
    "\n",
    "    calc_metrics(all_true_labels, all_predicted_labels, all_tokens)\n",
    "    print(\"PREDICTED:\")\n",
    "    show_box_markup(all_texts[show_sample_index],\n",
    "                    get_spans(all_predicted_labels[show_sample_index], all_tokens[show_sample_index]),\n",
    "                    palette=palette(PER=BLUE, ORG=RED, LOC=GREEN))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ARCH оценка кач-ва\n",
    "\n",
    "# model = char_ff_lstm_model\n",
    "# MAX_SEQ_LEN = 500\n",
    "\n",
    "# PATH_true_test = 'test_data/test_ner_only/'\n",
    "# PATH_pred_test = 'pred_ner_data/'\n",
    "\n",
    "# list_files = os.listdir(PATH_true_test)\n",
    "# ann_files = [x for x in list_files if x.endswith('ann')]\n",
    "\n",
    "# total_tp = 0\n",
    "# total_fp = 0\n",
    "# total_fn = 0\n",
    "\n",
    "# for ann_file in ann_files:\n",
    "#     ners_model = []\n",
    "#     segs, ners = read_data(PATH_true_test + ann_file)\n",
    "    \n",
    "#     # Test\n",
    "#     ann_test = []\n",
    "#     for text, spans in zip(segs, ners):\n",
    "#         ann_test.append(text_span_to_sample(text, spans))\n",
    "    \n",
    "#     ann_data = NerCharsDataset(ann_test, char_set)\n",
    "#     ann_loader = DataLoader(ann_data, batch_size=BATCH_SIZE)\n",
    "    \n",
    "#     model.eval()\n",
    "#     for batch_index, batch in enumerate(ann_loader):\n",
    "#         inputs, true_labels = batch\n",
    "#         batch_size = inputs.size(0)\n",
    "#         _, logits = model(inputs.to(\"cuda\"), true_labels.to(\"cuda\"))\n",
    "    \n",
    "#         output = logits.argmax(dim=1).detach().cpu()\n",
    "        \n",
    "#         for i in range(BATCH_SIZE * batch_index, BATCH_SIZE * (batch_index + 1)):\n",
    "#             tokens = list(tokenize(test_texts[i]))\n",
    "#             tokens = tokens[:MAX_SEQ_LEN]\n",
    "            \n",
    "#             indices = [i for i, x in enumerate(output[i]) if x != 0]\n",
    "#             indices_tensor = torch.Tensor(indices).type(torch.int64)\n",
    "            \n",
    "#             vals = output[0].gather(dim=0, index=indices_tensor)\n",
    "#             tokens_selected = [tokens[i] for i in indices]\n",
    "            \n",
    "#             for token, val in zip(tokens_selected, vals):\n",
    "#                 tag_id = int(val.item())\n",
    "    \n",
    "#                 ners_model.append((tag_id_2_tag[tag_id], token.start, token.stop))\n",
    "        \n",
    "#             tp, fp, fn = evaluate_ners.cacl_ner_tp_fp_fn(br_doc.ners, test_ners[i])\n",
    "#             total_tp += tp\n",
    "#             total_fp += fp\n",
    "#             total_fn += fn\n",
    "        \n",
    "#         break\n",
    "        \n",
    "#     br_doc = brat_format.read_file(PATH_true_test + ann_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# #     br_doc.ners = ners_model\n",
    "# #     br_doc.ner_id_2_idx = {k + 1: v for k, v in enumerate(range(len(ners_model)))}\n",
    "# #     br_doc.write_to_file(PATH_pred_test + ann_file)\n",
    "\n",
    "\n",
    "\n",
    "# precision, recall = evaluate_ners.compute_precision_and_recall(total_tp, total_fp, total_fn)\n",
    "# f_measure = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "## Перевожу ner в id, rel в id\n",
    "\n",
    "# # Делаем rel_2_rel_id\n",
    "# rel_2_rel_id = {}\n",
    "\n",
    "# for text_rel in relations:\n",
    "#     for i in range(len(text_rel)):\n",
    "#         text_rel[i] = list(text_rel[i])\n",
    "#         rel = text_rel[i]\n",
    "        \n",
    "#         if rel[2] not in rel_2_rel_id:\n",
    "#             rel_2_rel_id[rel[2]] = len(rel_2_rel_id)\n",
    "        \n",
    "#         #rel[2] = rel_2_rel_id[rel[2]]\n",
    "        \n",
    "# rel_id_2_rel = {v: k for k, v in rel_2_rel_id.items()}\n",
    "\n",
    "# # Делаем ner_2_ner_id\n",
    "# ner_2_ner_id = {}\n",
    "\n",
    "# for text_ner in ners:\n",
    "#     for i in range(len(text_ner)):\n",
    "#         text_ner[i] = list(text_ner[i])\n",
    "#         ner = text_ner[i]\n",
    "        \n",
    "#         if ner[2] not in ner_2_ner_id:\n",
    "#             ner_2_ner_id[ner[2]] = len(ner_2_ner_id)\n",
    "        \n",
    "#         #ner[2] = ner_2_ner_id[ner[2]]\n",
    "        \n",
    "# ner_id_2_ner = {v: k for k, v in ner_2_ner_id.items()}\n",
    "\n",
    "# Архив разделения на сегменты с relations\n",
    "\n",
    "# count_skip_rels = 0\n",
    "\n",
    "# count_chars = 0\n",
    "# cnt_global_ners = 0\n",
    "# ners_text = []\n",
    "# rels_text = []\n",
    "# for i in range(10):#[:10]:\n",
    "#     while br_doc.txt_data[count_chars] != segs[i][0]:\n",
    "#         count_chars += 1\n",
    "    \n",
    "#     seg = segs[i]\n",
    "#     end_seg = count_chars + len(seg)\n",
    "\n",
    "#     ners_this_seg = []\n",
    "#     relations_this_seg = []\n",
    "\n",
    "#     cnt_ners = 0\n",
    "#     while br_doc.ners and br_doc.ners[0][1] <= end_seg:\n",
    "#         ent = br_doc.ners.pop(0)\n",
    "#         cnt_ners += 1\n",
    "#         print(ent)\n",
    "#         ners_this_seg.append((ent[0] - count_chars, ent[1] - count_chars, ent[2]))\\\n",
    "    \n",
    "#     print('\\n')\n",
    "#     while br_doc.relations and br_doc.relations[0][1] < (cnt_global_ners + cnt_ners) and\\\n",
    "#         br_doc.relations[0][0] < (cnt_global_ners + cnt_ners):\n",
    "#         rel = br_doc.relations.pop(0)\n",
    "#         print(rel)\n",
    "        \n",
    "#         if rel[0] - cnt_global_ners < 0:\n",
    "#             count_skip_rels += 1\n",
    "#         else:\n",
    "#             relations_this_seg.append((rel[0] - cnt_global_ners, rel[1] - cnt_global_ners, rel[2]))\n",
    "        \n",
    "#     cnt_global_ners += cnt_ners\n",
    "#     count_chars += (len(seg) + 1)\n",
    "    \n",
    "#     ners_text.append(ners_this_seg)\n",
    "#     rels_text.append(relations_this_seg)\n",
    "    \n",
    "#     print('-' * 20, 'NER', '-' * 20)\n",
    "#     for ner in ners_this_seg:\n",
    "#         print(ner[0], ner[1], seg[ner[0]: ner[1]], ner[2])\n",
    "        \n",
    "#     print('\\n\\n')\n",
    "#     print('-' * 20, 'RELS', '-' * 20)\n",
    "    \n",
    "#     for rel in relations_this_seg:\n",
    "#         print(rel[0], rel[1])\n",
    "#         print(seg[ners_this_seg[rel[0]][0]: ners_this_seg[rel[0]][1]],\n",
    "#               seg[ners_this_seg[rel[1]][0]: ners_this_seg[rel[1]][1]],\n",
    "#               rel[2])\n",
    "        \n",
    "#     print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b1ea23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c2f904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21739a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc7a2dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c3247c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8b1724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402c4e03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e64f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c27e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009fcc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11e4442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a9b375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9ca863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2913054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4595aa56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb34ba01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9d3c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae0d14c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6739199e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6443cf47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7993b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd373a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ef8bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6332b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e2c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03310ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1b8d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1aee1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a345a750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e8f3c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0dc745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68749b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98340c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89960e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2163496b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc763c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee755dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b00c209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020f5f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1199c8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7df59fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33c4df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d06ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce38c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864aba5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722ad569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d92d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996ba9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4f2557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff39e1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8972e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df721ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee92587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720596b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb2ffc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3323121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8369efec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf623149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931940d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ceebb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575dfeff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc0595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b881f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea752af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afab7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff099294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a507a8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450e218b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46729ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84784739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31ba7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be2c01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
