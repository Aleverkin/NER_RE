{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48a506eb",
   "metadata": {},
   "source": [
    "Оцениваение: минимально в 2 раза больше обычного дз (если сделаете совсем много, возможны дополнительные бонусы).\n",
    "На чуть больше половины баллов за проект достаточно правильно сделать CharCNN-BLSTM-CRF для NER и вариант модели Miwa & Bansal (2016) для RE.\n",
    "Дедлайн 1 мая 9 утра (4 недели)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9221d095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import brat_format\n",
    "import os\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pickle \n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bbaba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_types = {\"OUT\", \"ACT\", \"BIN\", \"CMP\", \"ECO\", \"INST\", \"MET\", \"SOC\", \"QUA\"}\n",
    "# rel_types = {\"NNG\", \"NNT\", \"NPS\", \"FNG\", \"FNT\", \"FPS\", \"PNG\", \"PNT\", \"PPS\", \"GOL\", \"TSK\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e9551b",
   "metadata": {},
   "source": [
    "## Читаю данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ad6ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(ann_file):\n",
    "    br_doc = brat_format.read_file(ann_file)\n",
    "    segs = sent_tokenize(br_doc.txt_data, language=\"russian\")\n",
    "\n",
    "    count_chars = 0\n",
    "    cnt_global_ners = 0\n",
    "    ners_text = []\n",
    "    for i in range(len(segs)):\n",
    "        seg = segs[i]\n",
    "\n",
    "        while br_doc.txt_data[count_chars] != seg[0]:\n",
    "            count_chars += 1\n",
    "\n",
    "        end_seg = count_chars + len(seg)\n",
    "        ners_this_seg = []\n",
    "        while br_doc.ners and br_doc.ners[0][1] <= end_seg:\n",
    "            ent = br_doc.ners.pop(0)\n",
    "            #print(ent)\n",
    "            ners_this_seg.append((ent[0] - count_chars, ent[1] - count_chars, ent[2]))\n",
    "\n",
    "        count_chars += len(seg)\n",
    "        ners_text.append(ners_this_seg)\n",
    "\n",
    "    #     print('-' * 20, 'NER', '-' * 20)\n",
    "    #     for ner in ners_this_seg:\n",
    "    #         print(ner[0], ner[1], seg[ner[0]: ner[1]], ner[2])\n",
    "\n",
    "    #     print('\\n\\n\\n')\n",
    "    \n",
    "    return segs, ners_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c45b098",
   "metadata": {},
   "source": [
    "## READ TRAIN_VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08b6b648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10631 10631\n"
     ]
    }
   ],
   "source": [
    "train_val_texts, train_val_ners = [], [] \n",
    "\n",
    "for i in range(1, 4):\n",
    "    PATH = f'train_data/train_part_{i}/train_part_{i}/'\n",
    "    texts = []\n",
    "    ners = []\n",
    "\n",
    "    list_files = os.listdir(PATH)\n",
    "    ann_files = [x for x in list_files if x.endswith('ann')]\n",
    "    \n",
    "    for ann_file in ann_files:\n",
    "        segs, ners_file = read_data(PATH + ann_file)\n",
    "        \n",
    "        texts += segs\n",
    "        ners += ners_file\n",
    "    \n",
    "    train_val_texts += texts\n",
    "    train_val_ners += ners\n",
    "    \n",
    "print(len(train_val_texts), len(train_val_ners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06744a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295 \n",
      "\n",
      " Всего за 2015 год в районе:\n",
      " - введено   в эксплуатацию  - 18544 кв.м. площади, в т.ч. \n",
      "- 11090 кв. м. жилой, \n",
      "- выдано 153 разрешения на строительство, реконструкцию, капитальный ремонт объектов социальной сферы, жилых домов, газовых и электрических сетей,\n",
      "- введено в эксплуатацию 50 объектов. \n",
      "\n",
      "введено   в эксплуатацию BIN\n",
      "выдано BIN\n",
      "разрешения на строительство, реконструкцию, капитальный ремонт объектов социальной сферы, жилых домов, газовых и электрических сетей ACT\n",
      "введено в эксплуатацию BIN\n"
     ]
    }
   ],
   "source": [
    "i = 343\n",
    "\n",
    "print(len(train_val_texts[i]), '\\n\\n', train_val_texts[i], '\\n')\n",
    "\n",
    "for ner in train_val_ners[i]:\n",
    "    print(train_val_texts[i][ner[0]: ner[1]], ner[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df52a56c",
   "metadata": {},
   "source": [
    "## READ TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78bac4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19473 19473\n"
     ]
    }
   ],
   "source": [
    "PATH = 'test_data/test_ner_only/'\n",
    "\n",
    "list_files = os.listdir(PATH)\n",
    "ann_files = [x for x in list_files if x.endswith('ann')]\n",
    "\n",
    "test_texts = []\n",
    "test_ners = []\n",
    "for ann_file in ann_files:\n",
    "    segs, ners_text = read_data(PATH + ann_file)\n",
    "\n",
    "    test_texts += segs\n",
    "    test_ners += ners_text\n",
    "    \n",
    "print(len(test_texts), len(test_ners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41a84bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CMP', 'ACT', 'INST', 'ECO', 'MET', 'SOC', 'QUA', 'BIN'}\n",
      "{'OUT'}\n"
     ]
    }
   ],
   "source": [
    "train_val_ners_exist = set()\n",
    "\n",
    "for spans in train_val_ners:\n",
    "    for span in spans:\n",
    "        train_val_ners_exist.add(span[2])\n",
    "        \n",
    "print(train_val_ners_exist)\n",
    "print(ner_types - train_val_ners_exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b398d3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CMP', 'ACT', 'INST', 'ECO', 'MET', 'SOC', 'QUA', 'BIN'}\n",
      "{'OUT'}\n"
     ]
    }
   ],
   "source": [
    "test_ners_exist = set()\n",
    "\n",
    "for spans in test_ners:\n",
    "    for span in spans:\n",
    "        test_ners_exist.add(span[2])\n",
    "        \n",
    "print(test_ners_exist)\n",
    "print(ner_types - test_ners_exist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2988b000",
   "metadata": {},
   "source": [
    "## BIO\n",
    "\n",
    "BIO разметка: B - begin, I - inner, O - outer. Преобразуем задачу разметки спанов в задачу классификации каждого слова.\n",
    "\n",
    "0 = O = outer, 1 = B = begin, 2 = I = inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77d4f757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CMP': 1,\n",
       " 'ACT': 2,\n",
       " 'INST': 3,\n",
       " 'ECO': 4,\n",
       " 'MET': 5,\n",
       " 'SOC': 6,\n",
       " 'QUA': 7,\n",
       " 'BIN': 8,\n",
       " 'OUT': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_2_tag_id = {v: k + 1 for k, v in enumerate(ner_types - {'OUT'})}\n",
    "tag_2_tag_id['OUT'] = 0\n",
    "\n",
    "tag_id_2_tag = {v: k for k, v in tag_2_tag_id.items()}\n",
    "\n",
    "tag_2_tag_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40037a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import IntEnum\n",
    "from collections import namedtuple\n",
    "\n",
    "from razdel import tokenize\n",
    "\n",
    "from ipymarkup import show_box_markup\n",
    "from ipymarkup.palette import palette\n",
    "\n",
    "class Label(IntEnum):\n",
    "    OUTER = 0\n",
    "    BEGIN = 1\n",
    "    INNER = 2\n",
    "\n",
    "Sample = namedtuple(\"Sample\", \"text,tokens,spans,labels\")\n",
    "\n",
    "def text_span_to_sample(text, spans):\n",
    "    labels = []\n",
    "    tokens = list(tokenize(text))\n",
    "    \n",
    "    spans_copy = spans.copy()\n",
    "    for token in tokens:\n",
    "        label = tag_2_tag_id['OUT']\n",
    "        \n",
    "        if spans_copy:\n",
    "            span_begin, span_end, tag = spans_copy[0]\n",
    "\n",
    "            if token.start == span_begin or (token.start > span_begin and token.stop <= span_end):\n",
    "                label = tag_2_tag_id[tag]\n",
    "\n",
    "            if token.stop == span_end:\n",
    "                spans_copy.pop(0)\n",
    "            \n",
    "        labels.append(label)\n",
    "    \n",
    "    return Sample(text, tokens, spans, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "480770e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "train_val = []\n",
    "for text, spans in zip(train_val_texts, train_val_ners):\n",
    "    train_val.append(text_span_to_sample(text, spans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c5d8079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test = []\n",
    "for text, spans in zip(test_texts, test_ners):\n",
    "    test.append(text_span_to_sample(text, spans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acca3b2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">Глава <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">администрации<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">INST</span></span> \n",
       "муниципального района В.В. Бахвалов \n",
       "Приложение \n",
       "<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #c8e6c9; background: #e8f5e9\">Утверждена<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #66bb6a;\">BIN</span></span> \n",
       "постановлением <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">администрации<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">INST</span></span> \n",
       "Чухломского муниципального района \n",
       "Костромской области \n",
       "от « 21 » июля 2017 г .</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "10631\n"
     ]
    }
   ],
   "source": [
    "i = 9346\n",
    "\n",
    "show_box_markup(train_val[i].text, train_val[i].spans)\n",
    "print(train_val[i].labels)\n",
    "print(len(train_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99cd33da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">Основные итоги исполнения консолидированного\n",
       "<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">бюджета<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ECO</span></span> Владимирской <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">области<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ECO</span></span> и <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">бюджета<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ECO</span></span> территориального\n",
       "фонда обязательного медицинского страхования\n",
       "Владимирской области в 2016 году\n",
       "\n",
       "В 2016 году <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">мобилизовано<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ECO</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffe0b2; background: #fff3e0\">доходов<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #ffb74d;\">MET</span></span> в <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffe0b2; background: #fff3e0\">консолидированный<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #ffb74d;\">MET</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">бюджет области<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">ECO</span></span> в сумме 61,9 млрд. рублей, или 102,1% к плану года и 107,4% к уровню 2015 года.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 4, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 5, 0, 5, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "19473\n"
     ]
    }
   ],
   "source": [
    "i = 7\n",
    "\n",
    "show_box_markup(test[i].text, test[i].spans)\n",
    "print(test[i].labels)\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b262b64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10631"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbf8ebbc",
   "metadata": {
    "id": "IwyMhmAaE_CY"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(train_val)\n",
    "\n",
    "train = train_val[:9000]\n",
    "val = train_val[9000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f905538",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JEWpoWt6CkP1",
    "outputId": "2851693e-8c5f-4d98-950e-f5afb74b664d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', '<unk>', 's', 'Ә', 'N', '<', '\\uf0b7', 'H', '=', 'g', 'з', 'ф', 'ё', 'д', 'н', '8', 'С', 'R', 'ъ', '(', '7', 'п', 'х', 'O', '┤', 'A', 'П', 'т', 'v', 'u', '№', 'Х', 'б', 'Я', 'd', 'А', 'E', 'Щ', ',', 'Ю', '6', 'и', '1', '└', 'р', 'й', 'ж', 'э', 'x', 'l', 'Z', 'e', 'І', 'Ы', 'ч', 'Ц', '”', '┘', 'л', 'Ь', 'h', 'T', 'ь', '–', 'Ъ', 'с', '\"', 'G', 'щ', '.', 'Э', 'w', 'Р', 'z', '[', '…', '@', '┌', '3', 'p', 'S', '»', '×', '*', 'V', 'В', 'o', 'F', 'к', 'Г', 'I', 'ш', 'Н', 'W', 'Ж', '┼', 'Т', '«', 'Д', 'y', '┐', 'Б', '%', 'ә', 'j', 'М', 'о', 'm', 'г', 'D', 'а', 'k', '─', '!', 'О', '├', ']', '2', 'е', 'f', '“', 'b', 'ы', 'X', '0', 'Ё', 'Σ', 'U', 'Е', '-', 'З', '9', '_', '/', ')', 'я', 'К', 'a', 'У', '∑', 'Ö', 'M', 'Й', 'i', 'ю', ';', ':', 'C', '┬', 'Л', '>', '+', 'м', 'B', 'K', '■', '•', 'ц', '5', 'Ч', 'r', 'у', '£', '—', '│', 'җ', 'P', 'c', '4', 'И', 't', 'Ф', 'Ш', 'в', 'L', 'n']\n"
     ]
    }
   ],
   "source": [
    "char_set = [\"<pad>\", \"<unk>\"] + list({ch for sample in train for token in sample.tokens for ch in token.text})\n",
    "print(char_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc205fe8",
   "metadata": {
    "id": "Bl0XXI9_iNJQ"
   },
   "source": [
    "Для каждого слова сохраняем его символьный состав, а в остальном старый добрый пайплайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c59e320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10631.000000\n",
       "mean       231.197065\n",
       "std        286.775179\n",
       "min          1.000000\n",
       "0%           1.000000\n",
       "10%         10.000000\n",
       "20%         73.000000\n",
       "30%        105.000000\n",
       "40%        134.000000\n",
       "50%        166.000000\n",
       "60%        202.000000\n",
       "70%        248.000000\n",
       "80%        320.000000\n",
       "90%        461.000000\n",
       "max       7562.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat = []\n",
    "\n",
    "for i in range(len(train_val)):\n",
    "    stat.append(len(train_val[i].text))\n",
    "\n",
    "pd.Series(stat).describe(percentiles=[x/10 for x in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dcef6f8",
   "metadata": {
    "id": "ZBb2Ek8PmtJm"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "# from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "# class NerCharsDataset(Dataset):\n",
    "#     def __init__(self, samples, char_set, max_seq_len=500, max_char_seq_len=50):\n",
    "#         assert len(samples) != 0\n",
    "#         self.samples = []\n",
    "#         self.tokens = []\n",
    "#         self.texts = []\n",
    "#         for sample in samples:\n",
    "#             inputs = torch.zeros((max_seq_len, max_char_seq_len), dtype=torch.long)\n",
    "#             for token_num, token in enumerate(sample.tokens[:max_seq_len]):\n",
    "#                 for ch_num, ch in enumerate(token.text[:max_char_seq_len]):\n",
    "#                     char_index = char_set.index(ch) if ch in char_set else char_set.index(\"<unk>\")\n",
    "#                     inputs[token_num][ch_num] = char_index\n",
    "#             labels = torch.zeros((max_seq_len,), dtype=torch.long)\n",
    "#             input_labels = [int(i) for i in sample.labels[:max_seq_len]]\n",
    "#             labels[:len(input_labels)] = torch.LongTensor(input_labels)\n",
    "#             self.samples.append((torch.LongTensor(inputs), torch.LongTensor(labels)))\n",
    "#             self.tokens.append(sample.tokens[:max_seq_len])\n",
    "#             self.texts.append(sample.text)\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.samples)\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         return self.samples[index]\n",
    "\n",
    "#     def get_tokens(self, index):\n",
    "#         return self.tokens[index]\n",
    "    \n",
    "#     def get_text(self, index):\n",
    "#         return self.texts[index]\n",
    "\n",
    "\n",
    "# BATCH_SIZE = 128\n",
    "\n",
    "# train_data = NerCharsDataset(train, char_set)\n",
    "# train_sampler = RandomSampler(train_data)\n",
    "# train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "\n",
    "# val_data = NerCharsDataset(val, char_set)\n",
    "# val_loader = DataLoader(val_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "# test_data = NerCharsDataset(test, char_set)\n",
    "# test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75932023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample in train_loader:\n",
    "#     inputs, labels = sample\n",
    "#     print(inputs.size())\n",
    "#     print(labels.size())\n",
    "#     break\n",
    "\n",
    "# # inputs: batch_size x num_words x num_chars\n",
    "# # labels: batch_size x num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5a4036be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def get_next_gen_batch(samples, max_seq_len=500, max_char_seq_len=50, batch_size=128, shuffle=True):\n",
    "    indices = np.arange(len(samples))\n",
    "    if shuffle:\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "    batch_begin = 0\n",
    "    while batch_begin < len(samples):\n",
    "        batch_indices = indices[batch_begin: batch_begin + batch_size]\n",
    "        batch = []\n",
    "        batch_labels = []\n",
    "        batch_max_len = 0\n",
    "        for data_ind in batch_indices:\n",
    "            sample = samples[data_ind]\n",
    "            inputs = []\n",
    "            for token in sample.tokens[:max_seq_len]:\n",
    "                chars = [char_set.index(ch) if ch in char_set else char_set.index(\"<unk>\") for ch in token.text][:max_char_seq_len]\n",
    "                chars += [0] * (max_char_seq_len - len(chars))\n",
    "                inputs.append(chars)\n",
    "            batch_max_len = max(batch_max_len, len(inputs))\n",
    "            inputs += [[0]*max_char_seq_len] * (max_seq_len - len(inputs))\n",
    "            batch.append(inputs)\n",
    "            labels = sample.labels[:max_seq_len]\n",
    "            labels += [0] * (max_seq_len - len(labels))\n",
    "            batch_labels.append(labels)\n",
    "        batch_begin += batch_size\n",
    "        batch = torch.cuda.LongTensor(batch)[:, :batch_max_len]\n",
    "        labels = torch.cuda.LongTensor(batch_labels)[:, :batch_max_len]\n",
    "        yield batch_indices, batch, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a787c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Artem\\AppData\\Roaming\\Python\\Python36\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "def train_gen_model(model, train_samples, val_samples, epochs_count=50, \n",
    "                    loss_every_nsteps=1000, lr=0.01, save_path=\"model_30_04.pth\", device_name=\"cuda\",\n",
    "                    early_stopping=True):\n",
    "    params_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(\"Trainable params: {}\".format(params_count))\n",
    "    device = torch.device(device_name)\n",
    "    model = model.to(device)\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_function = nn.CrossEntropyLoss().cuda()\n",
    "    prev_avg_val_loss = None\n",
    "    for epoch in range(epochs_count):\n",
    "        model.train()\n",
    "        for step, (_, batch, batch_labels) in enumerate(get_next_gen_batch(train)):\n",
    "            logits = model(batch) # Прямой проход\n",
    "            logits = logits.transpose(1, 2)\n",
    "            loss = loss_function(logits, batch_labels) # Подсчёт ошибки\n",
    "            loss.backward() # Подсчёт градиентов dL/dw\n",
    "            optimizer.step() # Градиентный спуск или его модификации (в данном случае Adam)\n",
    "            optimizer.zero_grad() # Зануление градиентов, чтобы их спокойно менять на следующей итерации\n",
    "            total_loss += loss.item()\n",
    "        val_total_loss = 0\n",
    "        val_batch_count = 0\n",
    "        model.eval()\n",
    "        for _, (_, batch, batch_labels) in enumerate(get_next_gen_batch(val)):\n",
    "            logits = model(batch) # Прямой проход\n",
    "            logits = logits.transpose(1, 2)\n",
    "            val_total_loss += loss_function(logits, batch_labels) # Подсчёт ошибки\n",
    "            val_batch_count += 1\n",
    "        avg_val_loss = val_total_loss/val_batch_count\n",
    "        print(\"Epoch = {}, Avg Train Loss = {:.4f}, Avg val loss = {:.4f}, Time = {:.2f}s\".format(epoch, total_loss / loss_every_nsteps, avg_val_loss, time.time() - start_time))\n",
    "        total_loss = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        if early_stopping and prev_avg_val_loss is not None and avg_val_loss > prev_avg_val_loss:\n",
    "            model.load_state_dict(torch.load(save_path))\n",
    "            model.eval()\n",
    "            break\n",
    "        prev_avg_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1d44d6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch import nn\n",
    "\n",
    "# class SuperSimpleModel(nn.Module):\n",
    "#     def __init__(self, char_set_size, char_embedding_dim=16, classes_count=9, char_max_seq_len=50):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.embeddings_layer = nn.Embedding(char_set_size, char_embedding_dim)\n",
    "#         self.out_layer = nn.Linear(char_max_seq_len * char_embedding_dim, classes_count)\n",
    "\n",
    "#     def forward(self, inputs):\n",
    "#         projections = self.embeddings_layer.forward(inputs)\n",
    "#         projections = projections.reshape(projections.size(0), projections.size(1), -1)\n",
    "#         output = self.out_layer.forward(projections)\n",
    "#         return output\n",
    "\n",
    "\n",
    "# model = SuperSimpleModel(len(char_set))\n",
    "# train_gen_model(model, train, val, epochs_count=30, early_stopping=False, lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0fdef93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class CharFFLstmModel(nn.Module):\n",
    "    def __init__(self, char_set_size, char_embedding_dim=8, classes_count=9, word_embedding_dim=32, lstm_embedding_dim=32, char_max_seq_len=50):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embeddings_layer = nn.Embedding(char_set_size, char_embedding_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.linear = nn.Linear(char_embedding_dim * char_max_seq_len, word_embedding_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm_layer = nn.LSTM(word_embedding_dim, lstm_embedding_dim // 2, batch_first=True, bidirectional=True)\n",
    "        self.out_layer = nn.Linear(lstm_embedding_dim, classes_count)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        projections = self.embeddings_layer.forward(inputs)\n",
    "        projections = projections.reshape(projections.size(0), projections.size(1), -1)\n",
    "        projections = self.relu(self.linear(projections))\n",
    "        projections = self.dropout(projections)\n",
    "        output, _= self.lstm_layer(projections)\n",
    "        output = self.dropout(output)\n",
    "        output = self.out_layer.forward(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8fac825b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 37865\n",
      "Epoch = 0, Avg Train Loss = 0.0336, Avg val loss = 0.2767, Time = 10.78s\n",
      "Epoch = 1, Avg Train Loss = 0.0244, Avg val loss = 0.1869, Time = 9.94s\n",
      "Epoch = 2, Avg Train Loss = 0.0156, Avg val loss = 0.1799, Time = 9.99s\n",
      "Epoch = 3, Avg Train Loss = 0.0141, Avg val loss = 0.1682, Time = 10.28s\n",
      "Epoch = 4, Avg Train Loss = 0.0146, Avg val loss = 0.1740, Time = 9.91s\n",
      "Epoch = 5, Avg Train Loss = 0.0137, Avg val loss = 0.1727, Time = 10.31s\n",
      "Epoch = 6, Avg Train Loss = 0.0136, Avg val loss = 0.1501, Time = 10.08s\n",
      "Epoch = 7, Avg Train Loss = 0.0134, Avg val loss = 0.1521, Time = 9.83s\n",
      "Epoch = 8, Avg Train Loss = 0.0134, Avg val loss = 0.1459, Time = 10.27s\n",
      "Epoch = 9, Avg Train Loss = 0.0135, Avg val loss = 0.1495, Time = 9.76s\n",
      "Epoch = 10, Avg Train Loss = 0.0126, Avg val loss = 0.1496, Time = 10.29s\n",
      "Epoch = 11, Avg Train Loss = 0.0125, Avg val loss = 0.1476, Time = 10.38s\n",
      "Epoch = 12, Avg Train Loss = 0.0121, Avg val loss = 0.1260, Time = 10.34s\n",
      "Epoch = 13, Avg Train Loss = 0.0120, Avg val loss = 0.1224, Time = 10.12s\n",
      "Epoch = 14, Avg Train Loss = 0.0123, Avg val loss = 0.1431, Time = 9.85s\n",
      "Epoch = 15, Avg Train Loss = 0.0124, Avg val loss = 0.1196, Time = 9.75s\n",
      "Epoch = 16, Avg Train Loss = 0.0112, Avg val loss = 0.1354, Time = 9.92s\n",
      "Epoch = 17, Avg Train Loss = 0.0115, Avg val loss = 0.1074, Time = 9.96s\n",
      "Epoch = 18, Avg Train Loss = 0.0108, Avg val loss = 0.1152, Time = 10.07s\n",
      "Epoch = 19, Avg Train Loss = 0.0113, Avg val loss = 0.1251, Time = 9.84s\n",
      "Epoch = 20, Avg Train Loss = 0.0110, Avg val loss = 0.1120, Time = 9.83s\n",
      "Epoch = 21, Avg Train Loss = 0.0106, Avg val loss = 0.1122, Time = 9.78s\n",
      "Epoch = 22, Avg Train Loss = 0.0108, Avg val loss = 0.1144, Time = 10.05s\n",
      "Epoch = 23, Avg Train Loss = 0.0108, Avg val loss = 0.1176, Time = 9.90s\n",
      "Epoch = 24, Avg Train Loss = 0.0101, Avg val loss = 0.1186, Time = 9.89s\n",
      "Epoch = 25, Avg Train Loss = 0.0107, Avg val loss = 0.1053, Time = 10.40s\n",
      "Epoch = 26, Avg Train Loss = 0.0107, Avg val loss = 0.1147, Time = 9.54s\n",
      "Epoch = 27, Avg Train Loss = 0.0102, Avg val loss = 0.1050, Time = 9.89s\n",
      "Epoch = 28, Avg Train Loss = 0.0102, Avg val loss = 0.1154, Time = 9.83s\n",
      "Epoch = 29, Avg Train Loss = 0.0103, Avg val loss = 0.1284, Time = 9.82s\n",
      "Epoch = 30, Avg Train Loss = 0.0103, Avg val loss = 0.0985, Time = 9.92s\n",
      "Epoch = 31, Avg Train Loss = 0.0102, Avg val loss = 0.1102, Time = 9.78s\n",
      "Epoch = 32, Avg Train Loss = 0.0097, Avg val loss = 0.1149, Time = 10.11s\n",
      "Epoch = 33, Avg Train Loss = 0.0101, Avg val loss = 0.1057, Time = 10.07s\n",
      "Epoch = 34, Avg Train Loss = 0.0104, Avg val loss = 0.1085, Time = 10.14s\n",
      "Epoch = 35, Avg Train Loss = 0.0102, Avg val loss = 0.0962, Time = 10.20s\n",
      "Epoch = 36, Avg Train Loss = 0.0103, Avg val loss = 0.1102, Time = 9.80s\n",
      "Epoch = 37, Avg Train Loss = 0.0096, Avg val loss = 0.1000, Time = 10.15s\n",
      "Epoch = 38, Avg Train Loss = 0.0102, Avg val loss = 0.0975, Time = 10.06s\n",
      "Epoch = 39, Avg Train Loss = 0.0095, Avg val loss = 0.0968, Time = 10.09s\n",
      "Epoch = 40, Avg Train Loss = 0.0098, Avg val loss = 0.0970, Time = 10.01s\n",
      "Epoch = 41, Avg Train Loss = 0.0094, Avg val loss = 0.0906, Time = 10.28s\n",
      "Epoch = 42, Avg Train Loss = 0.0098, Avg val loss = 0.0991, Time = 10.51s\n",
      "Epoch = 43, Avg Train Loss = 0.0100, Avg val loss = 0.1141, Time = 10.02s\n",
      "Epoch = 44, Avg Train Loss = 0.0094, Avg val loss = 0.0980, Time = 9.97s\n",
      "Epoch = 45, Avg Train Loss = 0.0097, Avg val loss = 0.0952, Time = 10.22s\n",
      "Epoch = 46, Avg Train Loss = 0.0096, Avg val loss = 0.1125, Time = 9.81s\n",
      "Epoch = 47, Avg Train Loss = 0.0098, Avg val loss = 0.1010, Time = 9.84s\n",
      "Epoch = 48, Avg Train Loss = 0.0098, Avg val loss = 0.0981, Time = 9.96s\n",
      "Epoch = 49, Avg Train Loss = 0.0097, Avg val loss = 0.1000, Time = 9.78s\n",
      "Epoch = 50, Avg Train Loss = 0.0096, Avg val loss = 0.1031, Time = 9.91s\n",
      "Epoch = 51, Avg Train Loss = 0.0096, Avg val loss = 0.0934, Time = 10.33s\n",
      "Epoch = 52, Avg Train Loss = 0.0093, Avg val loss = 0.1009, Time = 10.14s\n",
      "Epoch = 53, Avg Train Loss = 0.0095, Avg val loss = 0.0943, Time = 9.57s\n",
      "Epoch = 54, Avg Train Loss = 0.0096, Avg val loss = 0.1063, Time = 10.04s\n",
      "Epoch = 55, Avg Train Loss = 0.0097, Avg val loss = 0.0961, Time = 9.93s\n",
      "Epoch = 56, Avg Train Loss = 0.0099, Avg val loss = 0.0996, Time = 9.73s\n",
      "Epoch = 57, Avg Train Loss = 0.0093, Avg val loss = 0.0997, Time = 9.85s\n",
      "Epoch = 58, Avg Train Loss = 0.0092, Avg val loss = 0.1063, Time = 10.13s\n",
      "Epoch = 59, Avg Train Loss = 0.0094, Avg val loss = 0.0988, Time = 10.26s\n",
      "Epoch = 60, Avg Train Loss = 0.0095, Avg val loss = 0.1006, Time = 10.03s\n",
      "Epoch = 61, Avg Train Loss = 0.0094, Avg val loss = 0.0901, Time = 10.23s\n",
      "Epoch = 62, Avg Train Loss = 0.0095, Avg val loss = 0.1006, Time = 10.14s\n",
      "Epoch = 63, Avg Train Loss = 0.0091, Avg val loss = 0.0926, Time = 10.12s\n",
      "Epoch = 64, Avg Train Loss = 0.0096, Avg val loss = 0.0979, Time = 10.05s\n",
      "Epoch = 65, Avg Train Loss = 0.0095, Avg val loss = 0.0946, Time = 9.98s\n",
      "Epoch = 66, Avg Train Loss = 0.0095, Avg val loss = 0.0971, Time = 10.11s\n",
      "Epoch = 67, Avg Train Loss = 0.0095, Avg val loss = 0.0922, Time = 10.04s\n",
      "Epoch = 68, Avg Train Loss = 0.0097, Avg val loss = 0.1051, Time = 10.23s\n",
      "Epoch = 69, Avg Train Loss = 0.0096, Avg val loss = 0.1057, Time = 10.18s\n",
      "Epoch = 70, Avg Train Loss = 0.0095, Avg val loss = 0.1012, Time = 9.98s\n",
      "Epoch = 71, Avg Train Loss = 0.0095, Avg val loss = 0.0975, Time = 10.22s\n",
      "Epoch = 72, Avg Train Loss = 0.0093, Avg val loss = 0.0974, Time = 9.87s\n",
      "Epoch = 73, Avg Train Loss = 0.0094, Avg val loss = 0.1009, Time = 9.88s\n",
      "Epoch = 74, Avg Train Loss = 0.0094, Avg val loss = 0.1015, Time = 10.15s\n",
      "Epoch = 75, Avg Train Loss = 0.0093, Avg val loss = 0.0930, Time = 9.96s\n",
      "Epoch = 76, Avg Train Loss = 0.0093, Avg val loss = 0.0909, Time = 9.97s\n",
      "Epoch = 77, Avg Train Loss = 0.0090, Avg val loss = 0.0927, Time = 10.17s\n",
      "Epoch = 78, Avg Train Loss = 0.0093, Avg val loss = 0.1055, Time = 9.88s\n",
      "Epoch = 79, Avg Train Loss = 0.0093, Avg val loss = 0.0929, Time = 9.96s\n",
      "Epoch = 80, Avg Train Loss = 0.0092, Avg val loss = 0.1016, Time = 9.93s\n",
      "Epoch = 81, Avg Train Loss = 0.0090, Avg val loss = 0.0908, Time = 9.97s\n",
      "Epoch = 82, Avg Train Loss = 0.0091, Avg val loss = 0.0875, Time = 9.84s\n",
      "Epoch = 83, Avg Train Loss = 0.0092, Avg val loss = 0.0891, Time = 9.83s\n",
      "Epoch = 84, Avg Train Loss = 0.0093, Avg val loss = 0.1043, Time = 9.72s\n",
      "Epoch = 85, Avg Train Loss = 0.0090, Avg val loss = 0.0995, Time = 9.94s\n",
      "Epoch = 86, Avg Train Loss = 0.0090, Avg val loss = 0.0997, Time = 9.84s\n",
      "Epoch = 87, Avg Train Loss = 0.0093, Avg val loss = 0.1061, Time = 9.77s\n",
      "Epoch = 88, Avg Train Loss = 0.0096, Avg val loss = 0.0997, Time = 9.97s\n",
      "Epoch = 89, Avg Train Loss = 0.0095, Avg val loss = 0.0969, Time = 9.78s\n",
      "Epoch = 90, Avg Train Loss = 0.0091, Avg val loss = 0.1023, Time = 9.84s\n",
      "Epoch = 91, Avg Train Loss = 0.0088, Avg val loss = 0.0937, Time = 10.13s\n",
      "Epoch = 92, Avg Train Loss = 0.0091, Avg val loss = 0.1097, Time = 9.65s\n",
      "Epoch = 93, Avg Train Loss = 0.0089, Avg val loss = 0.0868, Time = 9.95s\n",
      "Epoch = 94, Avg Train Loss = 0.0092, Avg val loss = 0.0871, Time = 9.89s\n",
      "Epoch = 95, Avg Train Loss = 0.0092, Avg val loss = 0.1017, Time = 9.80s\n",
      "Epoch = 96, Avg Train Loss = 0.0091, Avg val loss = 0.0941, Time = 10.01s\n",
      "Epoch = 97, Avg Train Loss = 0.0095, Avg val loss = 0.0906, Time = 9.94s\n",
      "Epoch = 98, Avg Train Loss = 0.0088, Avg val loss = 0.0928, Time = 10.00s\n",
      "Epoch = 99, Avg Train Loss = 0.0092, Avg val loss = 0.1038, Time = 9.69s\n"
     ]
    }
   ],
   "source": [
    "model = CharFFLstmModel(len(char_set), classes_count=len(ner_types))\n",
    "train_gen_model(model, train, val, epochs_count=150, early_stopping=False, lr=0.01, save_path=\"model_30_04_no_pl.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9882fe3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152K\tmodel_30_04.pth\n"
     ]
    }
   ],
   "source": [
    "! du -hs model_30_04_no_pl.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3aec414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"model_30_04_no_pl.pth\"\n",
    "\n",
    "model = CharFFLstmModel(len(char_set))\n",
    "model.load_state_dict(torch.load(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e84d834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharFFLstmModel(\n",
       "  (embeddings_layer): Embedding(176, 8)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (linear): Linear(in_features=400, out_features=64, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (lstm_layer): LSTM(64, 16, batch_first=True, bidirectional=True)\n",
       "  (out_layer): Linear(in_features=32, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da175602",
   "metadata": {},
   "source": [
    "# Оценка качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61889b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, batch, batch_labels = next(get_next_gen_batch(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aec52c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e8a72c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19473"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a4c05409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_index:  0\n",
      "batch_index:  100\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-f0bbb5761edf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mtokens_selected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mpred_tag_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-66-f0bbb5761edf>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mtokens_selected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mpred_tag_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import evaluate_ners\n",
    "\n",
    "MAX_SEQ_LEN = 500\n",
    "test_sizz = len(test)\n",
    "\n",
    "total_tp = 0\n",
    "total_fp = 0\n",
    "total_fn = 0\n",
    "\n",
    "global_true = []\n",
    "global_pred = []\n",
    "labels_pred = []\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n",
    "\n",
    "for batch_index, (indices, batch, batch_labels) in enumerate(get_next_gen_batch(test, shuffle=False)):\n",
    "    BATCH_SIZE = indices.shape[0]\n",
    "    logits = model(batch)\n",
    "    \n",
    "    predicted_labels = logits.argmax(dim=2).detach().cpu()\n",
    "    labels_pred.append(predicted_labels)\n",
    "    \n",
    "    for i in range(BATCH_SIZE):\n",
    "        num = batch_index * BATCH_SIZE + i\n",
    "        if num == test_sizz:\n",
    "            break\n",
    "        \n",
    "        #print('text: ', i)\n",
    "        ners_model = []\n",
    "        \n",
    "        tokens = list(tokenize(test_texts[num]))\n",
    "        tokens = tokens[:MAX_SEQ_LEN]\n",
    "\n",
    "        indices = [i for i, x in enumerate(predicted_labels[i]) if x != 0]\n",
    "        indices_tensor = torch.Tensor(indices).type(torch.int64)\n",
    "\n",
    "        vals = predicted_labels[i].gather(dim=0, index=indices_tensor)\n",
    "        tokens_selected = [tokens[i] for i in indices]\n",
    "\n",
    "        pred_tag_id = None\n",
    "        start = None\n",
    "        stop = None\n",
    "        for token, val in zip(tokens_selected, vals):\n",
    "            tag_id = int(val.item())\n",
    "            \n",
    "            if tag_id == pred_tag_id and token.start == stop + 1:\n",
    "                stop = token.stop\n",
    "            else:\n",
    "                if pred_tag_id is not None:\n",
    "                    ners_model.append((start, stop, tag_id_2_tag[pred_tag_id]))\n",
    "                    \n",
    "                pred_tag_id = tag_id\n",
    "                start = token.start\n",
    "                stop = token.stop\n",
    "                \n",
    "        if (len(tokens_selected) != 0 and\n",
    "            (len(ners_model) == 0 or ners_model[-1][1] != stop)):\n",
    "            ners_model.append((start, stop, tag_id_2_tag[pred_tag_id]))\n",
    "            \n",
    "        global_true.append(test_ners[i])\n",
    "        global_pred.append(ners_model)\n",
    "\n",
    "        tp, fp, fn = evaluate_ners.cacl_ner_tp_fp_fn(test_ners[i], ners_model)\n",
    "        total_tp += tp\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "        \n",
    "    if batch_index % 100 == 0:\n",
    "        print('batch_index: ', batch_index)\n",
    "        \n",
    "#     if batch_index == 1:\n",
    "#         break\n",
    "        \n",
    "precision, recall = evaluate_ners.compute_precision_and_recall(total_tp, total_fp, total_fn)\n",
    "f_measure = 2 * precision * recall / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d763d785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "582db04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, batch, batch_labels = next(get_next_gen_batch(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b2233c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae400d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = indices.shape[0]\n",
    "logits = model(batch)\n",
    "\n",
    "predicted_labels = logits.argmax(dim=2).detach().cpu()\n",
    "labels_pred.append(predicted_labels)\n",
    "\n",
    "for i in range(BATCH_SIZE):\n",
    "    num = batch_index * BATCH_SIZE + i\n",
    "    if num == test_sizz:\n",
    "        break\n",
    "\n",
    "    #print('text: ', i)\n",
    "    ners_model = []\n",
    "\n",
    "    tokens = list(tokenize(test_texts[num]))\n",
    "    tokens = tokens[:MAX_SEQ_LEN]\n",
    "\n",
    "    indices = [i for i, x in enumerate(predicted_labels[i]) if x != 0]\n",
    "    indices_tensor = torch.Tensor(indices).type(torch.int64)\n",
    "\n",
    "    vals = predicted_labels[i].gather(dim=0, index=indices_tensor)\n",
    "    tokens_selected = [tokens[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e347719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa0fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e03a2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163, 118609, 81011)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tp, total_fp, total_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6a8c7ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002008032128514056 0.0013723773279897618 0.0016304402188590918\n"
     ]
    }
   ],
   "source": [
    "precision, recall = evaluate_ners.compute_precision_and_recall(total_tp, total_fp, total_fn)\n",
    "f_measure = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(precision, recall, f_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ac6075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f4ec08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1834d190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ee862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaa39df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ec482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b7de8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n",
    "\n",
    "indices, batch, batch_labels = next(get_next_gen_batch(test))\n",
    "batch_size = batch.size()[0]\n",
    "logits = model(batch)\n",
    "\n",
    "predicted_labels = logits.argmax(dim=2).detach().cpu()\n",
    "#labels_pred.append(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f5a98682",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "3 3\n",
      "3 3\n",
      "3 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "8 0\n",
      "0 0\n",
      "0 0\n",
      "5 0\n",
      "5 0\n",
      "5 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "4 0\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "ind = 9\n",
    "\n",
    "for i, j in zip(train_val[ind].labels,  predicted_labels[ind]):\n",
    "    print(i, int(j.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed66945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f963a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_count=len(ner_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cef73a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = CRF(classes_count, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d83cf579",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions = torch.randn(BATCH_SIZE, 500, classes_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65e21b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, true_labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bef3750d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2d83cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-173546.2031, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(emissions, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39cd1081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1355.828125"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "173546 / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b0dcd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tags = 5  # number of tags is 5\n",
    "model = CRF(num_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f333eb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-12.0899, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = 3  # maximum sequence length in a batch\n",
    "batch_size = 2  # number of samples in the batch\n",
    "emissions = torch.randn(seq_length, batch_size, num_tags)\n",
    "tags = torch.tensor([\n",
    "            [0, 1], [2, 4], [3, 1]], dtype=torch.long)  # (seq_length, batch_size)\n",
    "model(emissions, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619b9914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c6e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f13579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "fe2deba3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 true:  [(353, 363, 'ECO'), (395, 406, 'BIN')] \t pred:  [(40, 74, 'INST'), (275, 288, 'INST'), (328, 338, 'BIN'), (341, 352, 'BIN'), (353, 363, 'ECO')]\n",
      "1 true:  [(0, 9, 'BIN')] \t pred:  [(0, 9, 'BIN'), (10, 19, 'ECO')]\n",
      "2 true:  [] \t pred:  []\n",
      "3 true:  [(82, 101, 'INST'), (103, 134, 'INST'), (136, 188, 'INST')] \t pred:  [(0, 8, 'ACT'), (12, 23, 'ACT'), (35, 48, 'ACT'), (113, 134, 'ECO'), (136, 145, 'ECO'), (146, 188, 'INST')]\n",
      "4 true:  [] \t pred:  []\n",
      "5 true:  [] \t pred:  []\n",
      "6 true:  [] \t pred:  [(62, 75, 'INST')]\n",
      "7 true:  [(45, 52, 'ECO'), (66, 73, 'ECO'), (76, 83, 'ECO'), (192, 204, 'ECO'), (205, 212, 'MET'), (215, 232, 'MET'), (233, 247, 'ECO')] \t pred:  [(45, 120, 'ECO'), (205, 239, 'ECO'), (240, 247, 'MET')]\n",
      "8 true:  [(0, 10, 'CMP'), (11, 18, 'MET'), (19, 29, 'BIN'), (38, 49, 'ECO'), (68, 101, 'ECO')] \t pred:  [(0, 29, 'ECO'), (38, 49, 'ECO'), (68, 101, 'ECO')]\n",
      "9 true:  [(12, 30, 'MET'), (61, 67, 'CMP')] \t pred:  [(12, 30, 'MET')]\n",
      "10 true:  [(0, 51, 'MET'), (53, 64, 'MET'), (65, 98, 'ECO'), (99, 109, 'CMP')] \t pred:  [(0, 51, 'MET'), (53, 91, 'MET'), (99, 109, 'CMP')]\n",
      "11 true:  [(0, 21, 'MET'), (22, 32, 'CMP')] \t pred:  [(0, 21, 'MET'), (22, 32, 'CMP')]\n",
      "12 true:  [(13, 28, 'MET'), (31, 50, 'MET')] \t pred:  [(13, 59, 'MET')]\n",
      "13 true:  [(0, 17, 'MET'), (74, 87, 'CMP')] \t pred:  [(0, 17, 'ECO')]\n",
      "14 true:  [(0, 30, 'MET'), (33, 39, 'MET')] \t pred:  [(0, 11, 'MET'), (12, 39, 'ECO')]\n",
      "15 true:  [(7, 13, 'ECO'), (25, 37, 'BIN'), (40, 46, 'ECO'), (94, 125, 'ECO')] \t pred:  [(7, 13, 'ECO'), (94, 100, 'ECO'), (104, 125, 'ECO')]\n",
      "16 true:  [(0, 35, 'MET'), (65, 79, 'ECO')] \t pred:  [(0, 35, 'MET'), (53, 62, 'MET'), (65, 71, 'MET')]\n",
      "17 true:  [(0, 59, 'ECO'), (77, 95, 'ECO')] \t pred:  [(0, 5, 'ECO'), (9, 42, 'ECO'), (45, 59, 'ECO'), (77, 95, 'ECO')]\n",
      "18 true:  [(3, 17, 'ECO'), (18, 27, 'BIN'), (30, 44, 'ECO')] \t pred:  [(3, 17, 'ECO')]\n",
      "19 true:  [(0, 25, 'ECO'), (29, 49, 'ECO'), (128, 135, 'ECO'), (156, 164, 'ECO'), (185, 194, 'ECO'), (220, 243, 'ECO'), (279, 284, 'ECO'), (296, 310, 'ECO'), (311, 314, 'INST')] \t pred:  [(0, 25, 'ECO'), (29, 49, 'ECO'), (72, 90, 'ECO'), (220, 232, 'ECO'), (296, 310, 'BIN'), (311, 314, 'ECO')]\n",
      "20 true:  [(0, 34, 'MET'), (35, 51, 'ECO')] \t pred:  [(0, 26, 'MET'), (27, 34, 'ECO'), (35, 51, 'MET')]\n",
      "21 true:  [(29, 55, 'MET')] \t pred:  [(9, 19, 'BIN'), (20, 47, 'MET'), (48, 55, 'ECO')]\n",
      "22 true:  [(19, 34, 'ECO'), (35, 45, 'BIN'), (46, 73, 'ECO')] \t pred:  [(10, 18, 'MET'), (19, 26, 'ECO'), (46, 53, 'SOC'), (57, 73, 'SOC')]\n",
      "23 true:  [] \t pred:  []\n",
      "24 true:  [(113, 119, 'CMP')] \t pred:  [(15, 28, 'BIN'), (41, 47, 'QUA'), (77, 84, 'ECO')]\n",
      "25 true:  [(0, 12, 'CMP'), (13, 20, 'MET'), (21, 26, 'CMP'), (27, 37, 'MET'), (38, 47, 'BIN'), (48, 75, 'ECO')] \t pred:  [(13, 34, 'MET'), (38, 75, 'MET')]\n",
      "26 true:  [(97, 115, 'ECO')] \t pred:  [(55, 73, 'ECO'), (106, 115, 'ECO')]\n",
      "27 true:  [(32, 40, 'ECO'), (110, 119, 'ECO'), (134, 141, 'ECO'), (190, 227, 'ECO')] \t pred:  [(0, 10, 'BIN'), (22, 40, 'ACT'), (44, 54, 'BIN'), (103, 119, 'MET'), (142, 160, 'MET'), (161, 168, 'ECO'), (190, 202, 'BIN'), (203, 227, 'ECO')]\n",
      "28 true:  [] \t pred:  [(40, 51, 'MET'), (54, 77, 'INST')]\n",
      "29 true:  [] \t pred:  [(3, 13, 'BIN')]\n",
      "30 true:  [(20, 29, 'CMP'), (30, 56, 'MET'), (57, 67, 'SOC'), (68, 73, 'ECO'), (74, 83, 'BIN'), (84, 92, 'QUA'), (93, 99, 'ECO')] \t pred:  [(20, 29, 'CMP'), (30, 83, 'MET'), (93, 99, 'MET')]\n",
      "31 true:  [(15, 44, 'MET'), (53, 66, 'MET'), (69, 76, 'INST')] \t pred:  []\n",
      "32 true:  [(353, 363, 'ECO'), (395, 406, 'BIN')] \t pred:  [(26, 36, 'ECO'), (37, 46, 'SOC')]\n",
      "33 true:  [(0, 9, 'BIN')] \t pred:  [(13, 30, 'MET')]\n",
      "34 true:  [] \t pred:  [(0, 19, 'MET'), (20, 56, 'ECO'), (74, 85, 'MET'), (86, 92, 'ECO')]\n",
      "35 true:  [(82, 101, 'INST'), (103, 134, 'INST'), (136, 188, 'INST')] \t pred:  [(20, 37, 'MET'), (38, 44, 'ECO')]\n",
      "36 true:  [] \t pred:  [(0, 36, 'MET'), (52, 58, 'QUA'), (61, 72, 'INST')]\n",
      "37 true:  [] \t pred:  [(0, 27, 'MET')]\n",
      "38 true:  [] \t pred:  []\n",
      "39 true:  [(45, 52, 'ECO'), (66, 73, 'ECO'), (76, 83, 'ECO'), (192, 204, 'ECO'), (205, 212, 'MET'), (215, 232, 'MET'), (233, 247, 'ECO')] \t pred:  [(12, 22, 'CMP'), (33, 46, 'INST'), (47, 68, 'MET'), (74, 83, 'BIN'), (85, 105, 'INST'), (133, 143, 'MET')]\n",
      "40 true:  [(0, 10, 'CMP'), (11, 18, 'MET'), (19, 29, 'BIN'), (38, 49, 'ECO'), (68, 101, 'ECO')] \t pred:  [(36, 44, 'CMP')]\n",
      "41 true:  [(12, 30, 'MET'), (61, 67, 'CMP')] \t pred:  [(8, 18, 'BIN'), (136, 146, 'BIN'), (147, 157, 'ECO'), (158, 168, 'BIN'), (169, 176, 'ECO'), (185, 191, 'MET'), (202, 213, 'MET')]\n",
      "42 true:  [(0, 51, 'MET'), (53, 64, 'MET'), (65, 98, 'ECO'), (99, 109, 'CMP')] \t pred:  [(0, 8, 'ECO'), (15, 32, 'ECO'), (88, 109, 'ECO'), (134, 143, 'ECO'), (304, 331, 'ACT'), (332, 369, 'ECO'), (370, 378, 'ACT'), (431, 442, 'ECO'), (482, 520, 'INST'), (551, 575, 'ACT'), (590, 597, 'ECO'), (598, 659, 'ACT'), (679, 686, 'ECO'), (690, 699, 'BIN'), (712, 718, 'ACT'), (734, 743, 'ACT'), (795, 884, 'ACT'), (906, 914, 'BIN'), (915, 922, 'ECO'), (923, 925, 'ACT'), (926, 959, 'ECO'), (964, 987, 'ECO'), (1003, 1014, 'BIN'), (1015, 1030, 'INST'), (1031, 1048, 'ACT'), (1049, 1060, 'INST'), (1061, 1072, 'ACT'), (1096, 1108, 'BIN'), (1111, 1121, 'BIN'), (1122, 1142, 'ACT'), (1143, 1155, 'ECO')]\n",
      "43 true:  [(0, 21, 'MET'), (22, 32, 'CMP')] \t pred:  [(0, 7, 'MET'), (8, 15, 'ECO'), (16, 32, 'MET'), (33, 38, 'ECO'), (39, 77, 'MET')]\n",
      "44 true:  [(13, 28, 'MET'), (31, 50, 'MET')] \t pred:  [(25, 122, 'ACT'), (205, 216, 'INST')]\n",
      "45 true:  [(0, 17, 'MET'), (74, 87, 'CMP')] \t pred:  [(12, 19, 'MET'), (23, 34, 'MET'), (61, 76, 'MET')]\n",
      "46 true:  [(0, 30, 'MET'), (33, 39, 'MET')] \t pred:  [(9, 27, 'ECO'), (46, 58, 'ECO'), (59, 72, 'INST'), (86, 93, 'ECO')]\n",
      "47 true:  [(7, 13, 'ECO'), (25, 37, 'BIN'), (40, 46, 'ECO'), (94, 125, 'ECO')] \t pred:  [(21, 32, 'ECO'), (36, 43, 'ECO'), (63, 76, 'INST'), (90, 101, 'INST'), (146, 165, 'ECO'), (178, 184, 'ECO'), (207, 216, 'ACT'), (217, 230, 'INST'), (231, 255, 'ACT'), (257, 270, 'ECO')]\n",
      "48 true:  [(0, 35, 'MET'), (65, 79, 'ECO')] \t pred:  [(20, 27, 'ECO'), (31, 64, 'ECO'), (68, 78, 'BIN'), (79, 93, 'QUA'), (112, 125, 'ECO'), (140, 152, 'BIN'), (155, 165, 'BIN'), (166, 186, 'ACT'), (187, 199, 'ECO')]\n",
      "49 true:  [(0, 59, 'ECO'), (77, 95, 'ECO')] \t pred:  [(81, 119, 'ECO'), (148, 156, 'ECO'), (211, 237, 'ECO')]\n",
      "50 true:  [(3, 17, 'ECO'), (18, 27, 'BIN'), (30, 44, 'ECO')] \t pred:  [(0, 10, 'MET'), (11, 33, 'ECO'), (34, 44, 'BIN'), (45, 62, 'MET'), (63, 124, 'ECO'), (171, 204, 'MET')]\n",
      "51 true:  [(0, 25, 'ECO'), (29, 49, 'ECO'), (128, 135, 'ECO'), (156, 164, 'ECO'), (185, 194, 'ECO'), (220, 243, 'ECO'), (279, 284, 'ECO'), (296, 310, 'ECO'), (311, 314, 'INST')] \t pred:  [(0, 8, 'ECO'), (9, 17, 'MET'), (21, 43, 'BIN'), (60, 66, 'ECO'), (137, 161, 'ECO')]\n",
      "52 true:  [(0, 34, 'MET'), (35, 51, 'ECO')] \t pred:  [(8, 102, 'ECO'), (183, 192, 'ECO'), (195, 288, 'ECO'), (312, 337, 'ECO'), (368, 408, 'ECO'), (417, 428, 'ECO'), (429, 440, 'BIN'), (441, 452, 'ACT'), (456, 467, 'BIN'), (468, 539, 'ACT'), (551, 573, 'ACT'), (586, 598, 'BIN'), (601, 611, 'BIN'), (612, 645, 'ACT')]\n",
      "53 true:  [(29, 55, 'MET')] \t pred:  []\n",
      "54 true:  [(19, 34, 'ECO'), (35, 45, 'BIN'), (46, 73, 'ECO')] \t pred:  [(8, 20, 'BIN'), (21, 31, 'ECO'), (114, 124, 'BIN'), (179, 186, 'ECO')]\n",
      "55 true:  [] \t pred:  [(134, 143, 'ECO'), (283, 298, 'ACT')]\n",
      "56 true:  [(113, 119, 'CMP')] \t pred:  [(20, 29, 'ECO'), (116, 140, 'ECO'), (141, 149, 'BIN')]\n",
      "57 true:  [(0, 12, 'CMP'), (13, 20, 'MET'), (21, 26, 'CMP'), (27, 37, 'MET'), (38, 47, 'BIN'), (48, 75, 'ECO')] \t pred:  [(22, 29, 'BIN'), (67, 84, 'ECO'), (104, 141, 'ECO'), (163, 175, 'ACT'), (176, 185, 'ECO'), (249, 260, 'BIN'), (343, 349, 'MET'), (390, 400, 'BIN')]\n",
      "58 true:  [(97, 115, 'ECO')] \t pred:  [(0, 9, 'ECO'), (21, 28, 'ECO'), (29, 39, 'BIN'), (57, 68, 'MET'), (103, 111, 'BIN'), (172, 195, 'ECO'), (208, 229, 'INST')]\n",
      "59 true:  [(32, 40, 'ECO'), (110, 119, 'ECO'), (134, 141, 'ECO'), (190, 227, 'ECO')] \t pred:  []\n",
      "60 true:  [] \t pred:  [(10, 19, 'BIN'), (29, 53, 'ECO'), (161, 169, 'MET'), (209, 233, 'MET'), (234, 242, 'CMP'), (291, 298, 'BIN'), (309, 318, 'ECO'), (321, 331, 'ECO'), (455, 463, 'BIN')]\n",
      "61 true:  [] \t pred:  [(28, 57, 'ECO'), (152, 160, 'MET'), (195, 207, 'BIN'), (230, 247, 'ECO')]\n",
      "62 true:  [(20, 29, 'CMP'), (30, 56, 'MET'), (57, 67, 'SOC'), (68, 73, 'ECO'), (74, 83, 'BIN'), (84, 92, 'QUA'), (93, 99, 'ECO')] \t pred:  [(45, 51, 'MET'), (75, 84, 'MET'), (85, 108, 'ECO'), (130, 144, 'ECO'), (146, 174, 'ACT'), (176, 187, 'ECO'), (190, 222, 'ECO')]\n",
      "63 true:  [(15, 44, 'MET'), (53, 66, 'MET'), (69, 76, 'INST')] \t pred:  [(24, 34, 'BIN'), (68, 77, 'BIN'), (91, 121, 'INST'), (124, 147, 'INST'), (149, 171, 'INST'), (237, 258, 'SOC'), (304, 314, 'BIN')]\n"
     ]
    }
   ],
   "source": [
    "for i, (true, pred) in enumerate(zip(global_true, global_pred)):\n",
    "    print(i, 'true: ', true, '\\t', 'pred: ', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "65966f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5db97c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fcc445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c5772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sber_emb",
   "language": "python",
   "name": "sber_emb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
